{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBGztCvgST42"
      },
      "outputs": [],
      "source": [
        "#Import library and dependencies\n",
        "import time\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import tensorflow.keras.backend as K\n",
        "import pennylane as qml\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBKfGyMcOk0b",
        "outputId": "c28cf2ae-b0bc-46eb-c72f-03772cd4b437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGIaZb-4PFcA",
        "outputId": "842221de-5b54-43a8-9f26-0a0fbe526f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.00000000e+00  1.70000000e+01  2.00000000e+00  2.60000000e+01\n",
            "  -8.93514148e-01]\n",
            " [ 2.00000000e+00  1.70000000e+01  2.00000000e+00  2.60100000e+01\n",
            "  -8.93357904e-01]\n",
            " [ 3.00000000e+00  1.70000000e+01  2.00000000e+00  2.60150000e+01\n",
            "  -8.93204131e-01]\n",
            " ...\n",
            " [ 1.48910000e+04  1.70000000e+01  2.00000000e+00  2.60150000e+01\n",
            "  -8.87039143e-01]\n",
            " [ 1.48920000e+04  1.70000000e+01  2.00000000e+00  2.60100000e+01\n",
            "  -8.87267666e-01]\n",
            " [ 1.48930000e+04  1.70000000e+01  2.00000000e+00  2.60000000e+01\n",
            "  -8.87505702e-01]]\n",
            "(14893, 5)\n",
            "Sheet2\n",
            "Sheet3\n",
            "Sheet4\n",
            "Sheet5\n",
            "Sheet6\n",
            "Sheet8\n",
            "Sheet9\n",
            "(119144, 5)\n",
            "no. of training points:  119144\n"
          ]
        }
      ],
      "source": [
        "no_of_output_nodes = 1\n",
        "df_1 = pd.read_excel('DSFdata.xlsx','Sheet1')\n",
        "datafile_1 = df_1.values\n",
        "print(datafile_1)\n",
        "print(df_1.shape)\n",
        "sheets = ['Sheet2', 'Sheet3','Sheet4', 'Sheet5', 'Sheet6', 'Sheet8', 'Sheet9']\n",
        "# sheets_names = []\n",
        "for sheet_name in sheets:\n",
        "    print(sheet_name)\n",
        "    df_sheet_name = pd.read_excel('/content/drive/MyDrive/DSFQMI/DSFdata.xlsx', sheet_name)\n",
        "    datafile_sheet_name = df_sheet_name.values\n",
        "    #########    combining data from all sheets of excel file    #########\n",
        "    datafile_1 = np.concatenate((datafile_1, datafile_sheet_name), axis=0)\n",
        "\n",
        "print(datafile_1.shape)\n",
        "########   just to see output variable values   ##########\n",
        "out_var_datafile_1 = datafile_1[:,range(1,2)]              ## stored output_variable (4th column) from xlsx file\n",
        "out_var_datafile_1 = out_var_datafile_1.reshape((-1,no_of_output_nodes))    ## one column with unknown no. of rows\n",
        "print('no. of training points: ', len(out_var_datafile_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHA70C2yoIPD"
      },
      "outputs": [],
      "source": [
        "#Normalize/Pre-process the data using MinMax scalar transformation\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler1.fit(datafile_1)\n",
        "scaler_datafile_1 = scaler1.transform(datafile_1)\n",
        "\n",
        "#Segregate data into Input variables X and output variable y\n",
        "xtrain  =scaler_datafile_1[:,0:4]\n",
        "ytrain = scaler_datafile_1[:,4:5]\n",
        "\n",
        "#Convert data into dataframe\n",
        "dataframe1 = pd.DataFrame(xtrain)\n",
        "dataframe2 = pd.DataFrame(ytrain)\n",
        "#Concatenate horizontally X and y variables for autoencoder training process\n",
        "original = pd.concat([dataframe1, dataframe2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7x7QRDAoIPE",
        "outputId": "d054952d-4cae-48f3-af1e-789cbd7465ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                384       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3109 (12.14 KB)\n",
            "Trainable params: 3109 (12.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Architecture of Autoencoder model1\n",
        "start_time = time.time()\n",
        "input = Input(shape=(5,))\n",
        "encoded = layers.Dense(64, activation='relu')(input)\n",
        "encoded = layers.Dense(16, activation='relu')(encoded)\n",
        "decoded = layers.Dense(16, activation='relu')(encoded)\n",
        "decoded = layers.Dense(64, activation='relu')(decoded)\n",
        "decoded = layers.Dense(5, activation='sigmoid')(decoded)\n",
        "autoencoder=Model(input, decoded)\n",
        "encoder = Model(input, encoded)\n",
        "\n",
        "#Compile and look at the summary of autoencoder 1 model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "autoencoder.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByIQ26eBo-5w",
        "outputId": "2c5045b8-9014-41fc-b5ea-a72ea230353e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "466/466 [==============================] - 5s 4ms/step - loss: 0.0200 - accuracy: 0.8490\n",
            "Epoch 2/2\n",
            "466/466 [==============================] - 2s 4ms/step - loss: 4.4688e-04 - accuracy: 0.9730\n",
            "end_time:  1706623402.4239578\n",
            "time taken to train in sec:  25.133506059646606\n"
          ]
        }
      ],
      "source": [
        "#Train the unsupervised autoencoder model with full data inclusive of input and output variables\n",
        "history = autoencoder.fit(original,original, epochs=2, batch_size=256)\n",
        "end_time = time.time()\n",
        "print('end_time: ', end_time)\n",
        "print('time taken to train in sec: ', (end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsFJ-R8ToIPG",
        "outputId": "78df2b6f-7a75-4817-ed1f-9bec6e89121f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3724/3724 [==============================] - 6s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#Augment the entire dataset for obtaining first batch of augmentation\n",
        "augmented = autoencoder.predict(original)\n",
        "Xaugtrain1000 = augmented[:,range(0,4)]\n",
        "yaugtrain1000 = augmented[:,range(4,5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VULhzTPoIPI",
        "outputId": "6fa63de6-0df0-479f-fe0e-1e1bfb69899c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "466/466 [==============================] - 3s 3ms/step - loss: 0.0081 - accuracy: 0.8636\n",
            "Epoch 2/2\n",
            "466/466 [==============================] - 2s 4ms/step - loss: 2.1442e-04 - accuracy: 0.9138\n",
            "end_time:  1706623417.5268552\n",
            "time taken to train in sec:  40.236403465270996\n"
          ]
        }
      ],
      "source": [
        "#Architecture of Autoencoder model2 and train with full dataset\n",
        "%matplotlib inline\n",
        "input = Input(shape=(5,))\n",
        "encoded = layers.Dense(128, activation='relu')(input)\n",
        "encoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(128, activation='relu')(decoded)\n",
        "decoded = layers.Dense(5, activation='sigmoid')(decoded)\n",
        "autoencoder1=Model(input, decoded)\n",
        "encoder = Model(input, encoded)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "autoencoder1.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
        "#autoencoder.summary()\n",
        "#Augment the X_train dataset\n",
        "history = autoencoder1.fit(original,original, epochs=2, batch_size=256)\n",
        "end_time = time.time()\n",
        "print('end_time: ', end_time)\n",
        "print('time taken to train in sec: ', (end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysnj0pdJoIPJ",
        "outputId": "58881e0a-1293-421d-cc03-aaba37a2685f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3724/3724 [==============================] - 7s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#Augment the entire dataset for obtaining second batch of augmentation\n",
        "augmented1 = autoencoder1.predict(original)\n",
        "Xaugtrain10001 = augmented1[:,range(0,4)]\n",
        "yaugtrain10001 = augmented1[:,range(4,5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOmuHIFLoIPK"
      },
      "outputs": [],
      "source": [
        "#Concatenate original set of data along with first and second batch of augmented/generated data samples to extend the dataset\n",
        "originalappended = np.concatenate([original, augmented, augmented1], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1KEFAQIoIPL",
        "outputId": "ca9480d9-e064-4efb-ecbe-4fb2ea4c900c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(357432, 5)\n"
          ]
        }
      ],
      "source": [
        "print(originalappended.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOeUehUXoIPN"
      },
      "outputs": [],
      "source": [
        "#After data augmenation, segregate the input variables X and output variables y\n",
        "xtrain11  =originalappended[:,0:4]\n",
        "ytrain11 = originalappended[:,4:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZw55STOTDhH"
      },
      "outputs": [],
      "source": [
        "#Apply downsampling process with factor D=100\n",
        "from scipy import signal\n",
        "ytrainsmall = signal.resample_poly(ytrain11, 100, 15000)\n",
        "xtrainsmall = signal.resample_poly(xtrain11, 100, 15000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQdaiY7zP9Eo",
        "outputId": "cd07e335-dd2b-4c39-8463-3516ea757d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2383, 4)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrainsmall.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHDow3scQF0q",
        "outputId": "74d2af3e-899c-476b-eaec-9c2b37c0a56a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2383, 1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytrainsmall.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehk0n3wrTH_f"
      },
      "outputs": [],
      "source": [
        "#Split data into Training and testing(inference with 2 trends of sensor data) set without shuffle\n",
        "x_trainval = xtrainsmall[:1668]\n",
        "y_trainval = ytrainsmall[:1668]\n",
        "x_inference = xtrainsmall[1668:]\n",
        "y_inference = ytrainsmall[1668:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cupXUCDjVWny"
      },
      "outputs": [],
      "source": [
        "#Build DQC (Dressed Quantum Circuit) based Quantum Regressor Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qq_hr_alzk-"
      },
      "outputs": [],
      "source": [
        "np.seterr(all='warn')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD3AEmO7RWMA"
      },
      "outputs": [],
      "source": [
        "#Define custom loss function for optimizing the QRM regerssor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CezZqme1Yyp8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def r_square(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Calculate L2 norms of y_true and y_pred\n",
        "    l2_norm_true = np.linalg.norm(y_true, axis=-1)\n",
        "    l2_norm_pred = np.linalg.norm(y_pred, axis=-1)\n",
        "    # Calculate the element-wise product\n",
        "    elementwise_product = l2_norm_true * l2_norm_pred\n",
        "    # Calculate the negative sum\n",
        "    lossl2 = -np.sum(elementwise_product)\n",
        "    return lossl2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV1ZWfo3M06N"
      },
      "outputs": [],
      "source": [
        "#Define Quantum node to construct Dressed quantum Circuit for the QRM regerssor\n",
        "import pennylane as qml\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)#, shots = 1500)\n",
        "\n",
        "@qml.qnode(dev, )\n",
        "def qnode(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "n_layers = 4\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
        "\n",
        "n_layers = 4\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
        "\n",
        "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za-2WyIT8N5C"
      },
      "outputs": [],
      "source": [
        "#Visualize the Quantum node\n",
        "# Generate random inputs and weights for the AngleEmbedding and StronglyEntanglingLayers\n",
        "inputs = np.random.rand(4)\n",
        "shape = qml.templates.StronglyEntanglingLayers.shape(n_layers=4, n_wires=4)\n",
        "weights = np.random.random(size=shape)\n",
        "qml.drawer.use_style('pennylane')\n",
        "\n",
        "# Visualize the combined circuit\n",
        "fig, ax = qml.draw_mpl(circuit, expansion_strategy=\"device\")(inputs, weights)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hxXGo2gObxD"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "def create_model():\n",
        "    clayer_1 = tf.keras.layers.Dense(4)\n",
        "    clayer_10 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "    clayer_11 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "    clayer_12 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "    clayer_2 = tf.keras.layers.Dense(1)\n",
        "    model = tf.keras.models.Sequential([clayer_1, qlayer, clayer_10, clayer_11, clayer_12, clayer_2])\n",
        "    adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    model.compile(loss='mean_squared_error', optimizer=adam,metrics=[custom_loss,'mae',r_square])\n",
        "    return model\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results for each fold\n",
        "mse_scores_per_fold = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(x_trainval), 1):\n",
        "    X_train, X_test = x_trainval[train_index], x_trainval[test_index]\n",
        "    y_train, y_test = y_trainval[train_index], y_trainval[test_index]\n",
        "\n",
        "    # Create the neural network model\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split = 0.3, verbose=2)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Store MSE score for the current fold\n",
        "    mse_scores_per_fold.append(mse)\n",
        "\n",
        "    # Print MSE for the current fold\n",
        "    print(\"Fold {}: MSE = {:.4f}\".format(fold, mse))\n",
        "\n",
        "# Plot a boxplot for each fold\n",
        "plt.boxplot(mse_scores_per_fold)\n",
        "plt.title('Boxplot of MSE Scores for Each Fold in K-Fold Cross Validation')\n",
        "plt.xlabel('Folds')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()\n",
        "\n",
        "# Print the mean and standard deviation of MSE scores across all folds\n",
        "print(\"\\nOverall Mean MSE: {:.4f}\".format(np.mean(mse_scores_per_fold)))\n",
        "print(\"Overall Standard Deviation of MSE: {:.4f}\".format(np.std(mse_scores_per_fold)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4P2rCm-Obxc"
      },
      "outputs": [],
      "source": [
        "# Plot a boxplot for each fold\n",
        "plt.boxplot(mse_scores_per_fold)\n",
        "plt.title('Boxplot of MSE Scores for Each Fold in K-Fold Cross Validation')\n",
        "plt.xlabel('Folds')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()\n",
        "\n",
        "# Print the mean and standard deviation of MSE scores across all folds\n",
        "print(\"\\nOverall Mean MSE: {:.4f}\".format(np.mean(mse_scores_per_fold)))\n",
        "print(\"Overall Standard Deviation of MSE: {:.4f}\".format(np.std(mse_scores_per_fold)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dykfj1u9GORS",
        "outputId": "18087e48-e06f-40f3-f8bb-631cbffc0112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'custom_loss', 'mae', 'r_square', 'val_loss', 'val_custom_loss', 'val_mae', 'val_r_square'])\n"
          ]
        }
      ],
      "source": [
        "#Get the training history of the QRM model\n",
        "\n",
        "history_dict = history.history\n",
        "print(history.history.keys())\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "# or save to csv:\n",
        "hist_csv_file = 'QRMBasic4Qubit4Layer1500Shotstrain.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FF3u2lDqMPT"
      },
      "outputs": [],
      "source": [
        "# summarize history for MSE Loss\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt\n",
        "fig1 = plt.gcf()\n",
        "plt.plot(history.history['loss'], linewidth=3)\n",
        "plt.plot(history.history['val_loss'], linewidth=3)\n",
        "plt.grid(True)\n",
        "plt.ylabel('Metrics', fontsize=12)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.legend(['Training'], loc='best', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yhIZVfCCSF0"
      },
      "outputs": [],
      "source": [
        "# summarize history for MSE Loss\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt\n",
        "fig1 = plt.gcf()\n",
        "plt.plot(history.history['custom_loss'], linewidth=3)\n",
        "plt.plot(history.history['val_custom_loss'], linewidth=3)\n",
        "plt.grid(True)\n",
        "plt.ylabel('Metrics', fontsize=12)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.legend(['Training'], loc='best', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvlXJNlhd4RK",
        "outputId": "55d60c8a-7cc6-420c-c30a-74c128703ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "#Save the model in joblib format\n",
        "from keras.models import load_model\n",
        "#model.save(SAVE_PATH +\"modelQReg5Qu100Shot2Qulaytrain.h5\")\n",
        "import joblib\n",
        "filename = 'modelQReg5Qu500Shot3Qulaytrain.model'\n",
        "joblib.dump(model, filename)\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwvhSorUoYfD"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    layer_1 = tf.keras.layers.Dense(4)\n",
        "    layer_2 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "    layer_3 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "    layer_4 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    model1 = tf.keras.Sequential([layer_1, layer_2,layer_3, layer_4])\n",
        "    adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    model1.compile(loss='mean_squared_error', optimizer=adam, metrics=[custom_loss,'mae',r_square])\n",
        "    return model1\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results for each fold\n",
        "mse_scores_per_fold = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(x_trainval), 1):\n",
        "    X_train, X_test = x_trainval[train_index], x_trainval[test_index]\n",
        "    y_train, y_test = y_trainval[train_index], y_trainval[test_index]\n",
        "\n",
        "    # Create the neural network model\n",
        "    model1 = create_model()\n",
        "\n",
        "    # Train the model\n",
        "    history1 = model1.fit(X_train, y_train, epochs=50, batch_size=128, validation_split = 0.3, verbose=2)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model1.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Store MSE score for the current fold\n",
        "    mse_scores_per_fold.append(mse)\n",
        "\n",
        "    # Print MSE for the current fold\n",
        "    print(\"Fold {}: MSE = {:.4f}\".format(fold, mse))\n",
        "\n",
        "# Plot a boxplot for each fold\n",
        "plt.boxplot(mse_scores_per_fold)\n",
        "plt.title('Boxplot of MSE Scores for Each Fold in K-Fold Cross Validation')\n",
        "plt.xlabel('Folds')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()\n",
        "\n",
        "# Print the mean and standard deviation of MSE scores across all folds\n",
        "print(\"\\nOverall Mean MSE: {:.4f}\".format(np.mean(mse_scores_per_fold)))\n",
        "print(\"Overall Standard Deviation of MSE: {:.4f}\".format(np.std(mse_scores_per_fold)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zYFb-ZBDfZg"
      },
      "outputs": [],
      "source": [
        "#Predict one single trend of DSF sensor data from Test set\n",
        "QRM= model.predict(x_test[25:100])\n",
        "ANNPred = model1.predict(x_test[25:100])\n",
        "#Denormalize the predicted values to plot it with original trend\n",
        "y03 = scaler1.inverse_transform(QRM)\n",
        "y04 = scaler1.inverse_transform(ANNPred[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noHe6haoDfdA"
      },
      "outputs": [],
      "source": [
        "#Extract one single trend of original DSF sensor data from Test set\n",
        "y01 = scaler1.inverse_transform(y_test[25:100])\n",
        "#Extract time parameter of one single trend of original DSF sensor data from Test set\n",
        "z01 = scaler1.inverse_transform(x_test[25:100])\n",
        "z01.reshape(-1,4)\n",
        "z01 = z01[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JeC-OnRDffj"
      },
      "outputs": [],
      "source": [
        "#Plot the comparison plot\n",
        "plt.figure()\n",
        "plt.plot(z01,y01,color='red',linewidth=3)\n",
        "plt.plot(z01,y03, color = 'blue',linewidth=3)\n",
        "plt.plot(z01,y04, color = 'lime',linewidth=3)\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Relative Power\")\n",
        "plt.legend(labels=[\"Actual\", \"Quantum Regressor Prediction\"])\n",
        "plt.tick_params(axis=\"both\", which=\"major\")\n",
        "plt.tick_params(axis=\"both\", which=\"minor\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy_x6uNmDfiX"
      },
      "outputs": [],
      "source": [
        "y01 = y_test\n",
        "ANNPred = model1.predict(x_test)\n",
        "yy1 =ANNPred[:]\n",
        "QRMPred = model.predict(x_test)\n",
        "y03 =QRMPred[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5HyE1PXDfk7"
      },
      "outputs": [],
      "source": [
        "#Plot the bubble plot\n",
        "xx = y01\n",
        "yy = y03\n",
        "yy1 =ANNPred[:]\n",
        "\n",
        "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
        "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
        "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
        "\n",
        "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x1y1, 'k-', linewidth=1.5)\n",
        "plt.grid(linestyle='--', linewidth=1)\n",
        "plt.scatter(xx, yy, label='Proposed quantum regressor model', marker='*', facecolors='', c='deeppink', s=50)\n",
        "plt.scatter(xx, yy1, label='ANN regressor', marker='*', facecolors='', c='lime', s=50)\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "\n",
        "plt.xlabel('Actual Relative Power', fontsize=10)\n",
        "plt.ylabel('Predicted Relative Power', fontsize=10 ,labelpad=0.8)\n",
        "plt.savefig('ActualPredictY1.png', dpi=300,bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tObLXY9XxfP3",
        "outputId": "9a20c4e5-e38f-4771-ba4d-a8483fdc9d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 3s 152ms/step\n"
          ]
        }
      ],
      "source": [
        "#Compute numerical performance metrics for proposed QRM model using test sample points\n",
        "QRM = model.predict(x_inference)\n",
        "from sklearn.metrics import r2_score\n",
        "R = r2_score(y_inference, QRM)\n",
        "print('R2 score for 50 Epochs: %.3f' % R) # Best should be 1\n",
        "from sklearn.metrics import explained_variance_score\n",
        "V = explained_variance_score(y_inference, QRM)\n",
        "print('Variance score for 50 Epochs: %.3f' % V) # Best should be 1\n",
        "from sklearn.metrics import max_error\n",
        "E = max_error(y_inference, QRM)\n",
        "print('Maximum error for 50 Epochs: %.3f' % E) # Best should be 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRc6QTQR9JP7"
      },
      "outputs": [],
      "source": [
        "#Compute numerical performance metrics for Artificial Neural Network model using test sample points\n",
        "ANN = model1.predict(x_inference)\n",
        "from sklearn.metrics import r2_score\n",
        "R = r2_score(y_inference,ANN)\n",
        "print('R2 score for 50 Epochs: %.3f' % R) # Best should be 1\n",
        "from sklearn.metrics import explained_variance_score\n",
        "V = explained_variance_score(y_inference, ANN)\n",
        "print('Variance score for 50 Epochs: %.3f' % V) # Best should be 1\n",
        "from sklearn.metrics import max_error\n",
        "E = max_error(y_inference, ANN)\n",
        "print('Maximum error for 50 Epochs: %.3f' % E) # Best should be 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE1uvGqo9JV6"
      },
      "outputs": [],
      "source": [
        "#Build and train SVR (Support Vector Regression) based Regressor Model\n",
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(x_trainval, np.ravel(y_trainval,order='C'))\n",
        "\n",
        "#Build and train RFR (Random Forest Regression) based Regressor Model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regr = RandomForestRegressor()\n",
        "regr.fit(x_trainval, np.ravel(y_trainval))\n",
        "\n",
        "#Build and train DTR (Decision Tree Regression) based Regressor Model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "DT = DecisionTreeRegressor(random_state=0)\n",
        "DT.fit(x_trainval, np.ravel(y_trainval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1TPMCmw9Q0c"
      },
      "outputs": [],
      "source": [
        "#Compute numerical performance metrics for SVR Regressor model using test sample points\n",
        "SVRPred = regressor.predict(x_inference)\n",
        "from sklearn.metrics import r2_score\n",
        "R = r2_score(y_inference,SVRPred)\n",
        "print('R2 score for 50 Epochs: %.3f' % R) # Best should be 1\n",
        "from sklearn.metrics import explained_variance_score\n",
        "V = explained_variance_score(y_inference, SVRPred)\n",
        "print('Variance score for 50 Epochs: %.3f' % V) # Best should be 1\n",
        "from sklearn.metrics import max_error\n",
        "E = max_error(y_inference, SVRPred)\n",
        "print('Maximum error for 50 Epochs: %.3f' % E) # Best should be 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsTzisSC9Q33"
      },
      "outputs": [],
      "source": [
        "#Compute numerical performance metrics for DT Regressor model using test sample points\n",
        "DTPred = DT.predict(x_inference)\n",
        "from sklearn.metrics import r2_score\n",
        "R = r2_score(y_inference,DTPred)\n",
        "print('R2 score for 50 Epochs: %.3f' % R) # Best should be 1\n",
        "from sklearn.metrics import explained_variance_score\n",
        "V = explained_variance_score(y_inference, DTPred)\n",
        "print('Variance score for 50 Epochs: %.3f' % V) # Best should be 1\n",
        "from sklearn.metrics import max_error\n",
        "E = max_error(y_inference, DTPred)\n",
        "print('Maximum error for 50 Epochs: %.3f' % E) # Best should be 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RcxDJ31bdRx"
      },
      "outputs": [],
      "source": [
        "#Compute numerical performance metrics for RF Regressor model using test sample points\n",
        "RFPred = regr.predict(x_inference)\n",
        "from sklearn.metrics import r2_score\n",
        "R = r2_score(y_inference,RFPred )\n",
        "print('R2 score for 50 Epochs: %.3f' % R) # Best should be 1\n",
        "from sklearn.metrics import explained_variance_score\n",
        "V = explained_variance_score(y_inference, RFPred )\n",
        "print('Variance score for 50 Epochs: %.3f' % V) # Best should be 1\n",
        "from sklearn.metrics import max_error\n",
        "E = max_error(y_inference, RFPred )\n",
        "print('Maximum error for 50 Epochs: %.3f' % E) # Best should be 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
